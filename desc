Designed and deployed an ETL pipeline that processed over 1 million records from the Spotify API, leveraging AWS Lambda for serverless automation and CloudWatch triggers to schedule extraction workflows, increasing data processing efficiency by 40%.
Built analytics-ready datasets by transforming raw JSON data using PySpark in AWS Glue, processing and structuring 500 GB of data monthly, and storing it in AWS S3 for scalable access, enabling downstream analysis and reporting.
Queried structured data in AWS Athena to deliver actionable insights on artist trends, song popularity, and user activity, optimizing analysis time by 30% compared to traditional workflows.

  Implement Complete Data Pipeline Data Engineering Project using Spotify

Integrating with Spotify API and extracting Data
Deploying code on AWS Lambda for Data Extraction
Adding trigger to run the extraction automatically
Writing transformation function
Building automated trigger on transformation function
Store files on S3 properly
Building Analytics Tables on data files using Glue and Athena

Technologies Used:
1. Spotify API
Purpose: The Spotify API provides access to Spotify's music data, including track details, artist information, albums, and user playlists. This API was the source of raw data for your ETL pipeline.
Usage:
Extracted metadata such as track names, artists, album details, and popularity metrics.
Leveraged API endpoints for dynamic and flexible data retrieval.
Implemented authentication using OAuth2 to securely interact with the API.
2. AWS Lambda
Purpose: A serverless compute service that allows you to run code without managing servers.
Usage:
Deployed Python scripts to extract and preprocess data from Spotify API.
Automated execution through triggers (e.g., scheduled time intervals using CloudWatch).
Ensured cost efficiency by charging only for the compute time used, ideal for intermittent data processing.
3. AWS S3 (Simple Storage Service)
Purpose: A scalable object storage service used for storing raw and transformed data.
Usage:
Stored raw JSON files from Spotify API in organized directories (e.g., raw_data/).
Saved transformed data into processed_data/ directories for analytics.
Ensured high durability and easy accessibility for ETL processes and downstream analytics.
4. AWS Glue
Purpose: A managed ETL service for preparing and transforming data at scale.
Usage:
Used PySpark scripts to process and clean raw Spotify data.
Automated ETL jobs to handle data transformation tasks, such as flattening nested JSON data and aggregating metrics.
Created metadata catalogs, enabling efficient schema discovery for downstream queries.
5. AWS Athena
Purpose: An interactive query service that enables SQL-like querying of data stored in S3.
Usage:
Queried transformed data stored in S3 to generate insights such as artist trends, song popularity, and user engagement metrics.
Allowed on-demand querying without requiring a dedicated database, reducing infrastructure costs.
Leveraged Glue Data Catalog as the schema layer for structured querying.
6. Python
Purpose: The core programming language used for ETL logic and integration.
Usage:
Wrote scripts for API interaction, data extraction, and transformation.
Utilized libraries such as boto3 for AWS service integration and pandas for lightweight transformations.
Implemented robust exception handling to ensure pipeline reliability.
7. CloudWatch (Triggers and Monitoring)
Purpose: A monitoring and management service for AWS resources.
Usage:
Scheduled Lambda functions using CloudWatch Events for periodic data extraction and transformation.
Monitored Lambda execution logs to ensure pipeline performance and debug issues.
How Each Technology Fits into the ETL Pipeline:
Extract:

Spotify API was used to fetch raw data about songs, albums, and artists.
Data was extracted in JSON format and pushed to AWS Lambda for initial processing.
Transform:

AWS Lambda performed lightweight data preprocessing (e.g., filtering unwanted fields).
AWS Glue handled large-scale transformations, such as flattening nested JSON files and aggregating metrics.
Load:

Processed data was saved into S3 in organized directories.
AWS Athena provided querying capabilities, allowing insights directly from S3 data.
